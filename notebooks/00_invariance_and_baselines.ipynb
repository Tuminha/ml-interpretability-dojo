{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 00: Invariance and Baselines\n",
        "\n",
        "## The Foundation of Model Understanding\n",
        "\n",
        "Before we dive into the sophisticated techniques of model interpretability, we must establish a solid foundation. This notebook introduces two fundamental concepts that every data scientist should understand:\n",
        "\n",
        "1. **Invariance**: The principle that well-behaved models should produce consistent predictions regardless of row order\n",
        "2. **Baselines**: Simple reference models that help us understand what \"random\" or \"naive\" performance looks like\n",
        "\n",
        "Understanding these concepts is crucial because they form the bedrock upon which all interpretability techniques are built. If a model isn't invariant to row shuffling, something is fundamentally wrong. If we don't know our baseline performance, we can't judge whether our model is actually learning anything useful.\n",
        "\n",
        "---\n",
        "\n",
        "## What is Invariance?\n",
        "\n",
        "In machine learning, **invariance** refers to the property that certain transformations of the input data should not change the model's predictions. For tabular data models (like linear regression, random forests, gradient boosting), one of the most basic invariances is **row-order invariance**.\n",
        "\n",
        "### Why Row Order Shouldn't Matter\n",
        "\n",
        "Consider a dataset of patient records. Whether we arrange patients alphabetically, by age, or completely randomly, a well-trained model should produce the same predictions for the same patients. The model learns patterns from the **features**, not from the **order** in which examples appear.\n",
        "\n",
        "Mathematically, if we have:\n",
        "- Original dataset: $X = [x_1, x_2, ..., x_n]^T$ with predictions $\\hat{y} = [\\hat{y}_1, \\hat{y}_2, ..., \\hat{y}_n]$\n",
        "- Permuted dataset: $X_{\\pi} = [x_{\\pi(1)}, x_{\\pi(2)}, ..., x_{\\pi(n)}]^T$ with predictions $\\hat{y}_{\\pi}$\n",
        "\n",
        "Then for a row-order invariant model: $\\hat{y}_{\\pi(i)} = \\hat{y}_i$ for all $i$.\n",
        "\n",
        "### When Invariance Breaks\n",
        "\n",
        "If shuffling rows changes predictions, it indicates:\n",
        "- **Data leakage**: The model is using information it shouldn't (e.g., row indices, temporal order)\n",
        "- **Implementation bugs**: The model or preprocessing pipeline has a bug\n",
        "- **Non-deterministic behavior**: Random seeds not set, causing different results\n",
        "\n",
        "Testing invariance is a **smoke test**—a quick check that catches fundamental problems before we invest time in deeper interpretability analysis.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Baselines Matter\n",
        "\n",
        "A **baseline model** is the simplest possible predictor that requires no machine learning. It serves as a reference point to answer: \"Is my fancy model actually better than doing nothing?\"\n",
        "\n",
        "### Regression Baseline: The Mean Predictor\n",
        "\n",
        "For regression tasks, the simplest baseline is to always predict the **mean** of the target variable:\n",
        "\n",
        "$$\\hat{y}_{baseline} = \\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_i$$\n",
        "\n",
        "This baseline has:\n",
        "- **RMSE**: Standard deviation of the target\n",
        "- **R²**: 0.0 (by definition, since it explains no variance)\n",
        "- **Interpretation**: \"If we knew nothing about features, we'd predict the average\"\n",
        "\n",
        "Any model that doesn't beat this baseline is essentially useless. A good model should have R² > 0 and RMSE < standard deviation of target.\n",
        "\n",
        "### Classification Baseline: The Majority Class\n",
        "\n",
        "For classification, the simplest baseline is to always predict the **most common class**:\n",
        "\n",
        "$$\\hat{y}_{baseline} = \\text{mode}(y)$$\n",
        "\n",
        "This baseline has:\n",
        "- **Accuracy**: Proportion of majority class\n",
        "- **Interpretation**: \"If we guessed the most common outcome every time, we'd be right X% of the time\"\n",
        "\n",
        "Any classifier that doesn't beat this baseline is worse than random guessing (for balanced classes) or worse than always guessing the majority (for imbalanced classes).\n",
        "\n",
        "---\n",
        "\n",
        "## The Importance of Random Seeds\n",
        "\n",
        "**Reproducibility** is essential in data science. Setting random seeds ensures that:\n",
        "- Train/test splits are consistent across runs\n",
        "- Model initialization is the same\n",
        "- Random shuffling produces the same order\n",
        "- Results are comparable and debuggable\n",
        "\n",
        "We'll use `seed=42` throughout this dojo (a popular choice, though any fixed number works). In production, you might use timestamps or commit hashes, but for learning, fixed seeds make experiments reproducible.\n",
        "\n",
        "---\n",
        "\n",
        "## What We'll Do in This Notebook\n",
        "\n",
        "1. **Load a regression dataset** (diabetes progression)\n",
        "2. **Fit a simple linear model** and establish baseline performance\n",
        "3. **Test invariance** by shuffling rows and comparing predictions\n",
        "4. **Compare to naive baseline** (mean predictor) to ensure our model learns something\n",
        "\n",
        "Let's begin!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n",
        "\n",
        "Let's start by importing the necessary libraries and setting up our environment for reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Set style for plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "from src.utils import set_seed\n",
        "set_seed(42)\n",
        "\n",
        "print(\"✓ Imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load the Dataset\n",
        "\n",
        "We'll use the diabetes dataset from scikit-learn, which is a classic regression problem. This dataset contains 10 baseline variables (age, sex, BMI, blood pressure, etc.) and a quantitative measure of disease progression one year after baseline.\n",
        "\n",
        "The dataset is small (442 samples) and fast to work with, making it perfect for learning interpretability concepts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Load a small regression dataset (diabetes). Split into X, y.\n",
        "# Hints: \n",
        "#   - Use load_diabetes(as_frame=True) to get a DataFrame\n",
        "#   - Extract X (features) and y (target) from the returned object\n",
        "#   - Print shapes of X and y to verify\n",
        "#   - Optionally print feature names\n",
        "\n",
        "# Acceptance:\n",
        "# - Print shapes of X and y\n",
        "# - X should be a DataFrame with 442 rows and 10 columns\n",
        "# - y should be a Series with 442 values\n",
        "# - Feature names should be displayed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Train-Test Split\n",
        "\n",
        "Before we fit any model, we need to split our data into training and testing sets. This ensures we can evaluate our model on unseen data, which gives us a more honest estimate of performance.\n",
        "\n",
        "We'll use an 80/20 split: 80% for training, 20% for testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.2, \n",
        "    random_state=42  # Fixed seed for reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Fit a Simple Linear Model\n",
        "\n",
        "Now let's fit a basic linear regression model. This will serve as our reference point for performance. Linear regression is interpretable by design—each coefficient tells us how much the target changes for a one-unit change in that feature (holding other features constant).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Fit a simple LinearRegression. Record test RMSE.\n",
        "# Hints:\n",
        "#   - Create a LinearRegression() object\n",
        "#   - Fit it on X_train, y_train\n",
        "#   - Make predictions on X_test\n",
        "#   - Compute RMSE: sqrt(mean_squared_error(y_test, y_pred))\n",
        "#   - Compute R²: r2_score(y_test, y_pred)\n",
        "#   - Print both metrics\n",
        "\n",
        "# Acceptance:\n",
        "# - Print RMSE_base (baseline RMSE for comparison)\n",
        "# - Print R² score\n",
        "# - Model should be fitted successfully\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Compare to Naive Baseline\n",
        "\n",
        "Before we test invariance, let's make sure our model is actually learning something useful. We'll compare our linear model to the simplest possible baseline: always predicting the mean of the training target.\n",
        "\n",
        "If our model doesn't beat this baseline, it's not learning anything meaningful.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute naive baseline: always predict the mean\n",
        "y_baseline = np.full_like(y_test, y_train.mean())\n",
        "rmse_baseline = np.sqrt(mean_squared_error(y_test, y_baseline))\n",
        "r2_baseline = r2_score(y_test, y_baseline)\n",
        "\n",
        "print(f\"Naive Baseline (mean predictor):\")\n",
        "print(f\"  RMSE: {rmse_baseline:.2f}\")\n",
        "print(f\"  R²: {r2_baseline:.4f}\")\n",
        "print(f\"\\nOur Linear Model:\")\n",
        "print(f\"  RMSE: {rmse_base:.2f}\")\n",
        "print(f\"  R²: {r2_base:.4f}\")\n",
        "print(f\"\\nImprovement:\")\n",
        "print(f\"  RMSE reduction: {((rmse_baseline - rmse_base) / rmse_baseline * 100):.1f}%\")\n",
        "print(f\"  R² improvement: {r2_base - r2_baseline:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Test Invariance\n",
        "\n",
        "Now for the key test: **Does shuffling the rows change our predictions?**\n",
        "\n",
        "If our model is well-behaved, the predictions for each test sample should remain the same, even if we reorder the test set. The only thing that should change is the order of the predictions themselves.\n",
        "\n",
        "We'll:\n",
        "1. Create a random permutation of the test set indices\n",
        "2. Reorder X_test and y_test according to this permutation\n",
        "3. Make predictions on the permuted test set\n",
        "4. Compare predictions: they should match the original predictions (just in a different order)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Reorder the test rows randomly and confirm predictions are identical up to permutation.\n",
        "# Hints:\n",
        "#   - Create a random permutation of indices: idx = np.random.permutation(len(X_test))\n",
        "#   - Reorder X_test: X_test_perm = X_test.iloc[idx] (or X_test[idx] if numpy array)\n",
        "#   - Reorder y_test: y_test_perm = y_test.iloc[idx] (or y_test[idx] if numpy array)\n",
        "#   - Make predictions on permuted test set\n",
        "#   - Compare: sort both prediction arrays and check if they're equal\n",
        "#   - Or: create a mapping and verify each prediction matches\n",
        "\n",
        "# Acceptance:\n",
        "# - Test set rows are randomly permuted\n",
        "# - Predictions are made on permuted test set\n",
        "# - Original and permuted predictions are compared\n",
        "# - Short Markdown note: row order does not change predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verification\n",
        "\n",
        "If invariance holds, the sorted predictions should be identical (or very close, accounting for floating-point precision). Let's verify:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify predictions are identical when sorted\n",
        "predictions_original_sorted = np.sort(y_pred_original)\n",
        "predictions_permuted_sorted = np.sort(y_pred_permuted)\n",
        "\n",
        "# Check if they're equal (within floating-point precision)\n",
        "are_identical = np.allclose(predictions_original_sorted, predictions_permuted_sorted)\n",
        "\n",
        "print(f\"Predictions are identical (up to permutation): {are_identical}\")\n",
        "if are_identical:\n",
        "    print(\"✓ Invariance test passed! Row order does not affect predictions.\")\n",
        "else:\n",
        "    print(\"⚠ Warning: Predictions differ. This suggests a problem with the model or data.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we've established two fundamental principles:\n",
        "\n",
        "1. **Invariance**: Well-behaved models produce consistent predictions regardless of row order. This is a basic sanity check that catches data leakage and implementation bugs.\n",
        "\n",
        "2. **Baselines**: Simple reference models (like the mean predictor) help us understand whether our model is actually learning useful patterns. If we can't beat a naive baseline, our model isn't useful.\n",
        "\n",
        "These concepts form the foundation for all interpretability work. In the next notebook, we'll explore **permutation importance**, which builds on the idea of invariance to measure feature importance.\n",
        "\n",
        "---\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- ✅ Row-order invariance is a fundamental property of tabular ML models\n",
        "- ✅ Always compare your model to a naive baseline\n",
        "- ✅ Random seeds ensure reproducibility\n",
        "- ✅ Testing invariance is a quick smoke test for model correctness\n",
        "\n",
        "**Next**: Notebook 01 will show you how to use permutation to measure feature importance!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
