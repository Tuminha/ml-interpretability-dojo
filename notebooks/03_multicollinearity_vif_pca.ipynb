{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03: Multicollinearity & PCA\n",
    "\n",
    "## Detecting Redundancy\n",
    "\n",
    "When features are highly correlated, coefficients become unstable and hard to interpret. Variance Inflation Factor (VIF) diagnoses the problem. Principal Component Analysis (PCA) reveals the underlying structure, rotating data to uncorrelated axes.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Multicollinearity?\n",
    "\n",
    "Multicollinearity occurs when features are highly correlated with each other. This causes:\n",
    "\n",
    "- **Unstable coefficients**: Small data changes cause large coefficient swings\n",
    "- **High variance**: Coefficients have large standard errors\n",
    "- **Uninterpretable results**: Coefficients don't reflect true feature importance\n",
    "\n",
    "## Variance Inflation Factor (VIF)\n",
    "\n",
    "VIF measures how much the variance of a coefficient increases due to multicollinearity. VIF > 10 indicates problematic multicollinearity.\n",
    "\n",
    "## Principal Component Analysis (PCA)\n",
    "\n",
    "PCA rotates data to uncorrelated axes (principal components) that capture maximum variance. It's a diagnostic tool for understanding feature redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path().resolve().parent if Path().resolve().name == 'notebooks' else Path().resolve()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.utils import set_seed\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"\u2713 Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split data\n",
    "data = load_diabetes(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize for VIF and PCA\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compute VIF\n",
    "\n",
    "VIF measures multicollinearity. VIF > 10 indicates problematic correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TODO: Compute VIF for numeric features after standardization\n",
    "# Hints:\n",
    "#   - Use variance_inflation_factor from statsmodels\n",
    "#   - Add constant column: add_constant(X_train_scaled_df)\n",
    "#   - Compute VIF for each feature\n",
    "#   - Flag features with VIF > 10\n",
    "# Acceptance: VIF table printed; flag VIF > 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: PCA Analysis\n",
    "\n",
    "PCA reveals the underlying structure and shows how many components capture most variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TODO: PCA on standardized X; plot cumulative explained variance\n",
    "# Hints:\n",
    "#   - Fit PCA on X_train_scaled\n",
    "#   - Compute cumulative explained variance\n",
    "#   - Plot scree plot (components vs explained variance)\n",
    "#   - Find number of components for 90% variance\n",
    "#   - Save to images/03_pca_scree_plot.png\n",
    "# Acceptance: Scree plot and number of components for 90% variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Optional - Refit on Principal Components\n",
    "\n",
    "Compare model performance using original features vs principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TODO: Optional: refit Ridge on top k principal components\n",
    "# Hints:\n",
    "#   - Transform X_train and X_test using PCA\n",
    "#   - Fit Ridge on principal components\n",
    "#   - Compare RMSE to original features\n",
    "# Acceptance: Report RMSE on PCs vs original features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "VIF diagnoses multicollinearity, PCA reveals underlying structure. Both help us understand feature redundancy.\n",
    "\n",
    "**Next**: Notebook 04 will explore SHAP values for model interpretability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}