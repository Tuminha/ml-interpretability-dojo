{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: SHAP Values\n",
    "\n",
    "## Unpacking Predictions\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) answers: \"How much did each feature contribute to this specific prediction?\" It's based on game theory, ensuring local attributions sum to the prediction minus baseline.\n",
    "\n",
    "---\n",
    "\n",
    "## What are SHAP Values?\n",
    "\n",
    "SHAP values provide **local explanations** for individual predictions. They satisfy:\n",
    "\n",
    "$$\\text{prediction} = \\text{baseline} + \\sum_{j=1}^{p} \\phi_j$$\n",
    "\n",
    "where $\\phi_j$ is the SHAP value for feature $j$.\n",
    "\n",
    "## Different Explainers\n",
    "\n",
    "- **LinearExplainer**: For linear models (fast, exact)\n",
    "- **TreeExplainer**: For tree models like XGBoost (fast, exact)\n",
    "- **KernelExplainer**: For any model (slow, approximate)\n",
    "\n",
    "## Performance Tips\n",
    "\n",
    "- Subsample to 500-1000 rows for SHAP\n",
    "- Use the right explainer for your model type\n",
    "- Fix random_state for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path().resolve().parent if Path().resolve().name == 'notebooks' else Path().resolve()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.utils import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "shap.initjs()  # Initialize JS visualization\n",
    "print(\"\u2713 Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_diabetes(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: SHAP for Linear Model\n",
    "\n",
    "Use LinearExplainer for Ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TODO: Fit Ridge, compute SHAP with LinearExplainer on 500-row sample\n",
    "# Hints:\n",
    "#   - Fit Ridge pipeline on standardized data\n",
    "#   - Create background sample (500 rows)\n",
    "#   - Use shap.LinearExplainer(model, background)\n",
    "#   - Compute SHAP values for test sample\n",
    "#   - Plot summary plot\n",
    "# Acceptance: SHAP summary plot; 2-sentence interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: SHAP for Tree Model\n",
    "\n",
    "Use TreeExplainer for XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TODO: Fit XGBoost, compute SHAP with TreeExplainer\n",
    "# Hints:\n",
    "#   - Fit XGBRegressor(n_estimators=200, max_depth=3)\n",
    "#   - Use shap.TreeExplainer(model)\n",
    "#   - Compute SHAP values for small test sample\n",
    "#   - Plot beeswarm plot\n",
    "# Acceptance: SHAP beeswarm plot; note top 3 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compare SHAP vs Permutation Importance\n",
    "\n",
    "Compare feature rankings from different interpretability methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TODO: Compare SHAP ranking vs permutation importance\n",
    "# Hints:\n",
    "#   - Get top 5 features from SHAP (mean absolute SHAP values)\n",
    "#   - Get top 5 features from permutation importance (from notebook 01)\n",
    "#   - Create comparison table\n",
    "# Acceptance: Table with top 5 features by each method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "SHAP provides local and global explanations. Different explainers for different models.\n",
    "\n",
    "**Next**: Notebook 05 will explore cross-validation schemes and data leakage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}